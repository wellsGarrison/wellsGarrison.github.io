{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spending data processing\n",
    "\n",
    "In this section I will process the data from the FEC to get the total amount spent by each presidential candidate in each state for the 2008, 2012, 2016, 2020, and 2024 elctions. \n",
    "\n",
    "Raw data is from here: https://www.fec.gov/data/candidates/president/presidential-map/ \n",
    "To get the data yourself, use the dropdown menu to select the electin year, open the tab on the side of the map for spending, and click \"Export spending data\". \n",
    "The files do not have labeled names so you need to label them accordingly, we have followed the pattern \"spending_data_{year}.csv\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import scipy\n",
    "from scipy.stats import wilcoxon\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import spending data of presidential candidates for the 2008, 2012, 2016, 2020, and 2024 elctions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2008', '2012', '2016', '2020', '2024']\n",
    "spending_dfs = dict()\n",
    "state_sums = dict()\n",
    "for year in years:\n",
    "    spending_dfs[year] = pd.read_csv(f\"spending_data_{year}.csv\", index_col=False, low_memory=False)\n",
    "    # state_sums[year] = spending_dfs[year].groupby('recipient_st').sum('disb_amt').sort_values('disb_amt')\n",
    "\n",
    "# spending_24_df = pd.read_csv(\"spending_data_2024.csv\", index_col=False, low_memory=False)\n",
    "# spending_24_df.groupby('recipient_st').sum('disb_amt').sort_values('disb_amt')\n",
    "# spending_24_df.head()\n",
    "# spending_dfs\n",
    "# state_sums['2024']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection some states have been labeled wrong. For example some rows have C, since they occur in san francisco we can assume this should be CA. \n",
    "\n",
    "For each year I have a comment labeling which abbreviations need to be replaced, for example in 2008 'AA' needs to be replaced by 'MA'. \n",
    "\n",
    "Most were done with a simple dictionary replace, but in 2024 some bad labels were for different states, for example zip codes in Iowa and Indiana were both labled 'I', so these require extra attention to replace them by zip code. \n",
    "\n",
    "Then once all errors are corrected we remove all rows where the recipient state is not one of the 50 US states or DC, for example some transactions are labled as \"UK\" which isn't useful for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct 2008 states \n",
    "spending_dfs['2008']['recipient_st']= spending_dfs['2008']['recipient_st'].replace({'AA': 'MA', 'C': 'CA', 'I': 'IA', 'II': 'IL', 'K': 'KS', 'KA': 'KS' , 'N': 'NC', 'VW': 'WV', '46': 'IN', 'MY': 'MT', 'OA': 'PA', 'T': 'TX', 'WW': 'WA'})\n",
    "\n",
    "# AA = MA\n",
    "# C = CA\n",
    "# I = IA\n",
    "# II = IL\n",
    "# K = KS\n",
    "# KA = KS \n",
    "# N = NC\n",
    "# VW = WV\n",
    "# 46 = IN\n",
    "# MY = MT\n",
    "# OA = PA\n",
    "# T = TX\n",
    "# WW = WA\n",
    "\n",
    "\n",
    "# correct 2012 states \n",
    "spending_dfs['2012']['recipient_st']= spending_dfs['2012']['recipient_st'].replace({'D.': 'DC', 'MY': 'NY', 'HA': 'HI', 'MH': 'NH', 'HN': 'NH'})\n",
    "\n",
    "# \"D.\" = \"DC\"\n",
    "# MY = NY\n",
    "# HA = HI\n",
    "# MH = NH\n",
    "# HN = HN\n",
    "\n",
    "# correct 2016 states \n",
    "spending_dfs['2016']['recipient_st']= spending_dfs['2016']['recipient_st'].replace({'D.': 'DC', 'MY': 'NY', 'HA': 'HI', 'MH': 'NH', 'HN': 'NH'})\n",
    "\n",
    "# NB = NE\n",
    "# D. = DC\n",
    "\n",
    "\n",
    "# correct 2020 states \n",
    "# none\n",
    "\n",
    "\n",
    "# correct 2024 states \n",
    "spending_dfs['2024']['recipient_st']= spending_dfs['2024']['recipient_st'].replace({'C': 'CA', 'AA': 'CA', 'F': 'FL', 'G': 'GA', 'T': 'TX'})\n",
    "spending_dfs['2024'].loc[spending_dfs['2024']['recipient_zip'] == '46038', 'recipient_st'] = 'IN'\n",
    "spending_dfs['2024']['recipient_st'] = spending_dfs['2024']['recipient_st'].replace('I', 'IA')\n",
    "spending_dfs['2024'].loc[spending_dfs['2024']['recipient_zip'] == '03276', 'recipient_st'] = 'NH'\n",
    "spending_dfs['2024'].loc[spending_dfs['2024']['recipient_zip'] == '03063', 'recipient_st'] = 'NH'\n",
    "spending_dfs['2024']['recipient_st'] = spending_dfs['2024']['recipient_st'].replace('N', 'NY')\n",
    "spending_dfs['2024'].loc[spending_dfs['2024']['recipient_zip'] == '19802', 'recipient_st'] = 'NJ'\n",
    "\n",
    "# C = CA,\n",
    "# AA = CA\n",
    "# F = FL\n",
    "# G = GA\n",
    "# T = TX\n",
    "# I = IN or IA\n",
    "# N = NH or NY\n",
    "\n",
    "\n",
    "states = [\n",
    "        'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'FL', 'GA', 'IA', \n",
    "        'IL', 'IN', 'LA', 'MA', 'MD', 'ME', 'MN', 'MO', 'NC', 'NE', \n",
    "        'NH', 'NJ', 'NY', 'OK', 'PA', 'SC', 'TN', 'TX', 'VA', 'SD',\n",
    "        'WA', 'WI', 'WY', 'OH', 'WV', 'AK', 'DE', 'HI', 'ID', 'KS', \n",
    "        'KY', 'MI', 'MS', 'MT', 'ND', 'NM', 'NV', 'OR', 'RI', 'UT', \n",
    "        'VT'\n",
    "        ]\n",
    "\n",
    "# remove transactions not in the 50 states or DC\n",
    "for year in spending_dfs:\n",
    "    spending_dfs[year] = spending_dfs[year][spending_dfs[year]['recipient_st'].isin(states)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to remove the candidates that aren't either the Democratic or Republican nominee, while other candidates exist they don't receive a significant amount of votes. This will leave us with a dataframe per candidate per election year, so 10 in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_spending_dfs = {}\n",
    "\n",
    "# 2008\n",
    "# Republican: 'McCain, John S'\n",
    "# Dem : 'Obama, Barack'\n",
    "# spending_dfs['2008'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'].isin(['McCain, John S', 'Obama, Barack'])]\n",
    "party_spending_dfs['2008_R'] = spending_dfs['2008'][spending_dfs['2008']['cand_nm'] == 'McCain, John S']\n",
    "party_spending_dfs['2008_D'] = spending_dfs['2008'][spending_dfs['2008']['cand_nm'] == 'Obama, Barack']\n",
    "\n",
    "# 2012\n",
    "# Rep: 'Romney, Mitt'\n",
    "# Dem: 'Obama, Barack'\n",
    "# spending_dfs['2012'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'].isin(['Romney, Mitt', 'Obama, Barack'])]\n",
    "party_spending_dfs['2012_R'] = spending_dfs['2012'][spending_dfs['2012']['cand_nm'] == 'Romney, Mitt']\n",
    "party_spending_dfs['2012_D'] = spending_dfs['2012'][spending_dfs['2012']['cand_nm'] == 'Obama, Barack']\n",
    "\n",
    "# 2016\n",
    "# Rep: 'Trump, Donald J.'\n",
    "# Dem: 'Clinton, Hillary Rodham'\n",
    "# spending_dfs['2016'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'].isin(['Trump, Donald J.', 'Clinton, Hillary Rodham'])]\n",
    "party_spending_dfs['2016_R'] = spending_dfs['2016'][spending_dfs['2016']['cand_nm'] == 'Trump, Donald J.']\n",
    "party_spending_dfs['2016_D'] = spending_dfs['2016'][spending_dfs['2016']['cand_nm'] == 'Clinton, Hillary Rodham']\n",
    "\n",
    "# 2020\n",
    "# Rep: 'Trump, Donald J.'\n",
    "# Dem: 'Biden, Joseph R Jr'\n",
    "# spending_dfs['2020'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'].isin(['Trump, Donald J.', 'Biden, Joseph R Jr'])]\n",
    "party_spending_dfs['2020_R'] = spending_dfs['2020'][spending_dfs['2020']['cand_nm'] == 'Trump, Donald J.']\n",
    "party_spending_dfs['2020_D'] = spending_dfs['2020'][spending_dfs['2020']['cand_nm'] == 'Biden, Joseph R Jr']\n",
    "\n",
    "# 2024\n",
    "# Rep: 'Trump, Donald J.'\n",
    "# Dem: 'Harris, Kamala' \n",
    "# spending_dfs['2024'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'].isin(['Trump, Donald J.', 'Harris, Kamala'])]\n",
    "party_spending_dfs['2024_R'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'] == 'Trump, Donald J.']\n",
    "party_spending_dfs['2024_D'] = spending_dfs['2024'][spending_dfs['2024']['cand_nm'] == 'Harris, Kamala']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nebraska and Maine split their electoral votes, 1 vote goes to the popular winner in each congressional district while 2 votes go to the popular winner of the whole state. So we will duplicate spending in Nebraska and Maine to count towards the overall state and the district it happened in, since later these will be predicted seperatley. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008_R ['OMAHA' 'NORFOLK' 'SOUTH SIOUX CITY']\n",
      "2008_D ['ELM CREEK' 'OMAHA' 'YORK' 'NORTH PLATTE' '800-2289872' 'S. SIOUX CITY'\n",
      " 'LINCOLN' 'SEWARD' 'KIMBALL' 'GRAND ISLAND' 'WACO' 'AURORA' 'KEARNEY'\n",
      " 'SUTHERLAND' 'N. PLATTE' 'OGALLALA' 'NEW YORK' 'SIDNEY' 'NORFOLK'\n",
      " 'LEXINGTON' 'COZAD' 'GERING' 'SOUTH SIOUX CITY' 'WINNEBAGO' 'LA VISTA'\n",
      " 'MCCOOK' 'SUITE 270']\n",
      "2008_R ['GRAY' 'S PORTLAND' 'AUGUSTA' 'SOUTH PORTLAND' 'PORTLAND' 'SCARBOROUGH'\n",
      " 'KENNEBUNKPORT' 'BREWER' 'BANGOR' 'PRESQUE ISLE' 'ORONO' 'AUBURN'\n",
      " 'PALMYRA' 'CORRINA']\n",
      "2008_D ['SCARBOROUGH' 'CAPE ELIZABETH' 'BIDDEFORD' 'PORTLAND' 'BRUNSWICK'\n",
      " 'CHINA VILLAGE' 'KITTERY' 'WINTHROP' 'BELFAST' 'ORONO' 'LEWISTON'\n",
      " 'CAPE NEDDICK' 'WATERVILLE' 'AUGUSTA' 'BANGOR' 'SACO' 'SOUTH PORTLAND'\n",
      " 'KENNEBUNK' 'WOOLWICH' 'CAMDEN' 'HAMPTDEN' 'LINCOLN' 'PRESQUE ISLE']\n"
     ]
    }
   ],
   "source": [
    "# for year, df in party_spending_dfs.items():\n",
    "#     print(year, df[df['recipient_st'].isin(['NE', 'ME'])]['recipient_city'].unique())\n",
    "\n",
    "year = '2008'\n",
    "print(f'{year}_R', party_spending_dfs[f'{year}_R'][party_spending_dfs[f'{year}_R']['recipient_st'] == 'NE']['recipient_city'].unique())\n",
    "print(f'{year}_D', party_spending_dfs[f'{year}_D'][party_spending_dfs[f'{year}_D']['recipient_st'] == 'NE']['recipient_city'].unique())\n",
    "\n",
    "print(f'{year}_R', party_spending_dfs[f'{year}_R'][party_spending_dfs[f'{year}_R']['recipient_st'] == 'ME']['recipient_city'].unique())\n",
    "print(f'{year}_D', party_spending_dfs[f'{year}_D'][party_spending_dfs[f'{year}_D']['recipient_st'] == 'ME']['recipient_city'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2008 \n",
    "NE_1_2008 = ['NORFOLK', 'SOUTH SIOUX CITY', 'S. SIOUX CITY', 'SEWARD', 'NORFOLK', 'WINNEBAGO', 'LINCOLN']\n",
    "NE_2_2008 = ['OMAHA', '800-2289872', 'NEW YORK', 'LA VISTA', 'SUITE 270']\n",
    "NE_3_2008 = ['ELM CREEK', 'YORK', 'NORTH PLATTE', 'KIMBALL', 'GRAND ISLAND', 'WACO', 'AURORA','KEARNEY', \n",
    "             'SUTHERLAND', 'N. PLATTE', 'OGALLALA', 'SIDNEY', 'LEXINGTON', 'COZAD', 'GERING', 'MCCOOK']\n",
    "\n",
    "ME_1_2008 = ['GRAY', 'S PORTLAND', 'AUGUSTA', 'SOUTH PORTLAND', 'PORTLAND', 'SCARBOROUGH', 'KENNEBUNKPORT', \n",
    "             'CAPE ELIZABETH', 'BIDDEFORD', 'BRUNSWICK', 'CHINA VILLAGE', 'KITTERY', 'WINTHROP', 'LEWISTON', \n",
    "             'CAPE NEDDICK', 'SACO', 'KENNEBUNK', 'WOOLWICH', 'CAMDEN']\n",
    "ME_2_2008 = ['BREWER', 'BANGOR', 'PRESQUE ISLE', 'ORONO', 'AUBURN', 'PALMYRA', 'CORRINA', 'BELFAST',\n",
    "             'WATERVILLE', 'HAMPTDEN']\n",
    "\n",
    "# 2012\n",
    "# Nebraksa used the same districts from 2003-2013\n",
    "NE_1_2012 = ['SOUTH SIOUX CITY', 'LINCOLN']\n",
    "NE_2_2012 = ['OMAHA', 'LAVISTA', 'BELLEVUE']\n",
    "NE_3_2012 = ['GRAND ISLAND']\n",
    "\n",
    "# Maine used the same districts from 2003-2013\n",
    "ME_1_2012 = ['S. PORTLAND', 'AUGUSTA', 'SOUTH PORTLAND', 'PORTLAND', 'SCARBOROUGH', 'LEWISTON', \n",
    "             'KENNEBUNK', 'FREEPORT', 'WESTBROOK', 'FARMINGDALE', 'WATERVILLE', 'RICHMOND']\n",
    "ME_2_2012 = ['BREWER', 'BETHEL', 'OXFORD', 'MACHIAS', 'HAMPDEN']\n",
    "\n",
    "# 2016 \n",
    "NE_1_2016 = [' LINCOLN', 'LINCOLN']\n",
    "NE_2_2016 = ['OMAHA']\n",
    "NE_3_2016 = ['SOUTH SIOUX CITY', 'HASTINGS']\n",
    "\n",
    "ME_1_2016 = ['BIDDEFORD', 'RICHMOND', 'SCARBOROUGH', 'PORTLAND', 'SOUTH PORTLAND', 'AUGUSTA', 'SACO',\n",
    "             'BATH', 'ROCKPORT', 'FALMOUTH', 'WELLS', 'LISBON', 'ROCKLAND']\n",
    "ME_2_2016 = ['BANGOR', 'BELFAST', 'LEWISTON', 'ELLSWORTH']\n",
    "\n",
    "# 2020 \n",
    "NE_1_2020 = []\n",
    "NE_2_2020 = ['OMAHA', 'PAPILLION']\n",
    "NE_3_2020 = ['KEARNEY']\n",
    "\n",
    "ME_1_2020 = ['AUGUSTA', 'PORTLAND', 'SACO', 'SCARBOROUGH', 'OLD ORCHARD BEACH', 'CAMDEN', 'BATH']\n",
    "ME_2_2020 = ['LEWSITON', 'LEWISTON', 'BANGOR', 'PALMYRA', 'HERMON', 'ORRINGTON', 'NORTH ANSON', 'MACHIAS', \n",
    "             'HOLDEN', 'SOUTH PARIS', 'BAR HARBOR', 'ELLSWORTH', 'PRESQUE ISLE', 'SOUTHWEST HARBOR',\n",
    "             'ELLSWORTH', 'STONINGTON', 'BREWER', 'FORT FAIRFIELD']\n",
    "\n",
    "# 2024\n",
    "NE_1_2024 = []\n",
    "NE_2_2024 = ['OMAHA', 'BOYS TOWN']\n",
    "NE_3_2024 = ['HASTINGS']\n",
    "\n",
    "ME_1_2024 = ['SCARBOROUGH', 'LEBANON', 'PORTLAND', 'YORK BEACH']\n",
    "ME_2_2024 = ['BANGOR']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that locations are separated by district we can add the new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_2008\n",
    "R_2008_NE_new = party_spending_dfs['2008_R'][party_spending_dfs['2008_R']['recipient_st'] == 'NE'].copy()\n",
    "R_2008_NE_new.loc[R_2008_NE_new['recipient_city'].isin(NE_1_2008), 'recipient_st'] = 'NE-1'\n",
    "R_2008_NE_new.loc[R_2008_NE_new['recipient_city'].isin(NE_2_2008), 'recipient_st'] = 'NE-2'\n",
    "R_2008_NE_new.loc[R_2008_NE_new['recipient_city'].isin(NE_3_2008), 'recipient_st'] = 'NE-3'\n",
    "# R_2008_NE_new = None \n",
    "\n",
    "R_2008_ME_new = party_spending_dfs['2008_R'][party_spending_dfs['2008_R']['recipient_st'] == 'ME'].copy()\n",
    "R_2008_ME_new.loc[R_2008_ME_new['recipient_city'].isin(ME_1_2008), 'recipient_st'] = 'ME-1'\n",
    "R_2008_ME_new.loc[R_2008_ME_new['recipient_city'].isin(ME_2_2008), 'recipient_st'] = 'ME-2'\n",
    "# R_2008_ME_new = None\n",
    "\n",
    "# D_2008\n",
    "D_2008_NE_new = party_spending_dfs['2008_D'][party_spending_dfs['2008_D']['recipient_st'] == 'NE'].copy()\n",
    "D_2008_NE_new.loc[D_2008_NE_new['recipient_city'].isin(NE_1_2008), 'recipient_st'] = 'NE-1'\n",
    "D_2008_NE_new.loc[D_2008_NE_new['recipient_city'].isin(NE_2_2008), 'recipient_st'] = 'NE-2'\n",
    "D_2008_NE_new.loc[D_2008_NE_new['recipient_city'].isin(NE_3_2008), 'recipient_st'] = 'NE-3'\n",
    "# D_2008_NE_new = None\n",
    "\n",
    "D_2008_ME_new = party_spending_dfs['2008_D'][party_spending_dfs['2008_D']['recipient_st'] == 'ME'].copy()\n",
    "D_2008_ME_new.loc[D_2008_ME_new['recipient_city'].isin(ME_1_2008), 'recipient_st'] = 'ME-1'\n",
    "D_2008_ME_new.loc[D_2008_ME_new['recipient_city'].isin(ME_2_2008), 'recipient_st'] = 'ME-2'\n",
    "# D_2008_ME_new = None\n",
    "\n",
    "# R_2012\n",
    "R_2012_NE_new = party_spending_dfs['2012_R'][party_spending_dfs['2012_R']['recipient_st'] == 'NE'].copy()\n",
    "R_2012_NE_new.loc[R_2012_NE_new['recipient_city'].isin(NE_1_2012), 'recipient_st'] = 'NE-1'\n",
    "R_2012_NE_new.loc[R_2012_NE_new['recipient_city'].isin(NE_2_2012), 'recipient_st'] = 'NE-2'\n",
    "R_2012_NE_new.loc[R_2012_NE_new['recipient_city'].isin(NE_3_2012), 'recipient_st'] = 'NE-3'\n",
    "# R_2012_NE_new = None \n",
    "\n",
    "R_2012_ME_new = party_spending_dfs['2012_R'][party_spending_dfs['2012_R']['recipient_st'] == 'ME'].copy()\n",
    "R_2012_ME_new.loc[R_2012_ME_new['recipient_city'].isin(ME_1_2012), 'recipient_st'] = 'ME-1'\n",
    "R_2012_ME_new.loc[R_2012_ME_new['recipient_city'].isin(ME_2_2012), 'recipient_st'] = 'ME-2'\n",
    "# R_2012_ME_new = None\n",
    "\n",
    "# D_2012\n",
    "D_2012_NE_new = party_spending_dfs['2012_D'][party_spending_dfs['2012_D']['recipient_st'] == 'NE'].copy()\n",
    "D_2012_NE_new.loc[D_2012_NE_new['recipient_city'].isin(NE_1_2012), 'recipient_st'] = 'NE-1'\n",
    "D_2012_NE_new.loc[D_2012_NE_new['recipient_city'].isin(NE_2_2012), 'recipient_st'] = 'NE-2'\n",
    "D_2012_NE_new.loc[D_2012_NE_new['recipient_city'].isin(NE_3_2012), 'recipient_st'] = 'NE-3'\n",
    "# D_2012_NE_new = None\n",
    "\n",
    "D_2012_ME_new = party_spending_dfs['2012_D'][party_spending_dfs['2012_D']['recipient_st'] == 'ME'].copy()\n",
    "D_2012_ME_new.loc[D_2012_ME_new['recipient_city'].isin(ME_1_2012), 'recipient_st'] = 'ME-1'\n",
    "D_2012_ME_new.loc[D_2012_ME_new['recipient_city'].isin(ME_2_2012), 'recipient_st'] = 'ME-2'\n",
    "# D_2012_ME_new = None\n",
    "\n",
    "# R_2016\n",
    "R_2016_NE_new = party_spending_dfs['2016_R'][party_spending_dfs['2016_R']['recipient_st'] == 'NE'].copy()\n",
    "R_2016_NE_new.loc[R_2016_NE_new['recipient_city'].isin(NE_1_2016), 'recipient_st'] = 'NE-1'\n",
    "R_2016_NE_new.loc[R_2016_NE_new['recipient_city'].isin(NE_2_2016), 'recipient_st'] = 'NE-2'\n",
    "R_2016_NE_new.loc[R_2016_NE_new['recipient_city'].isin(NE_3_2016), 'recipient_st'] = 'NE-3'\n",
    "# R_2016_NE_new = None \n",
    "\n",
    "R_2016_ME_new = party_spending_dfs['2016_R'][party_spending_dfs['2016_R']['recipient_st'] == 'ME'].copy()\n",
    "R_2016_ME_new.loc[R_2016_ME_new['recipient_city'].isin(ME_1_2016), 'recipient_st'] = 'ME-1'\n",
    "R_2016_ME_new.loc[R_2016_ME_new['recipient_city'].isin(ME_2_2016), 'recipient_st'] = 'ME-2'\n",
    "# R_2016_ME_new = None\n",
    "\n",
    "# D_2016\n",
    "D_2016_NE_new = party_spending_dfs['2016_D'][party_spending_dfs['2016_D']['recipient_st'] == 'NE'].copy()\n",
    "D_2016_NE_new.loc[D_2016_NE_new['recipient_city'].isin(NE_1_2016), 'recipient_st'] = 'NE-1'\n",
    "D_2016_NE_new.loc[D_2016_NE_new['recipient_city'].isin(NE_2_2016), 'recipient_st'] = 'NE-2'\n",
    "D_2016_NE_new.loc[D_2016_NE_new['recipient_city'].isin(NE_3_2016), 'recipient_st'] = 'NE-3'\n",
    "# D_2016_NE_new = None\n",
    "\n",
    "D_2016_ME_new = party_spending_dfs['2016_D'][party_spending_dfs['2016_D']['recipient_st'] == 'ME'].copy()\n",
    "D_2016_ME_new.loc[D_2016_ME_new['recipient_city'].isin(ME_1_2016), 'recipient_st'] = 'ME-1'\n",
    "D_2016_ME_new.loc[D_2016_ME_new['recipient_city'].isin(ME_2_2016), 'recipient_st'] = 'ME-2'\n",
    "# D_2016_ME_new = None\n",
    "\n",
    "# R_2020\n",
    "R_2020_NE_new = party_spending_dfs['2020_R'][party_spending_dfs['2020_R']['recipient_st'] == 'NE'].copy()\n",
    "R_2020_NE_new.loc[R_2020_NE_new['recipient_city'].isin(NE_1_2020), 'recipient_st'] = 'NE-1'\n",
    "R_2020_NE_new.loc[R_2020_NE_new['recipient_city'].isin(NE_2_2020), 'recipient_st'] = 'NE-2'\n",
    "R_2020_NE_new.loc[R_2020_NE_new['recipient_city'].isin(NE_3_2020), 'recipient_st'] = 'NE-3'\n",
    "# R_2020_NE_new = None \n",
    "\n",
    "R_2020_ME_new = party_spending_dfs['2020_R'][party_spending_dfs['2020_R']['recipient_st'] == 'ME'].copy()\n",
    "R_2020_ME_new.loc[R_2020_ME_new['recipient_city'].isin(ME_1_2020), 'recipient_st'] = 'ME-1'\n",
    "R_2020_ME_new.loc[R_2020_ME_new['recipient_city'].isin(ME_2_2020), 'recipient_st'] = 'ME-2'\n",
    "# R_2020_ME_new = None\n",
    "\n",
    "# D_2020\n",
    "D_2020_NE_new = party_spending_dfs['2020_D'][party_spending_dfs['2020_D']['recipient_st'] == 'NE'].copy()\n",
    "D_2020_NE_new.loc[D_2020_NE_new['recipient_city'].isin(NE_1_2020), 'recipient_st'] = 'NE-1'\n",
    "D_2020_NE_new.loc[D_2020_NE_new['recipient_city'].isin(NE_2_2020), 'recipient_st'] = 'NE-2'\n",
    "D_2020_NE_new.loc[D_2020_NE_new['recipient_city'].isin(NE_3_2020), 'recipient_st'] = 'NE-3'\n",
    "# D_2024_NE_new = None\n",
    "\n",
    "D_2020_ME_new = party_spending_dfs['2020_D'][party_spending_dfs['2020_D']['recipient_st'] == 'ME'].copy()\n",
    "D_2020_ME_new.loc[D_2020_ME_new['recipient_city'].isin(ME_1_2020), 'recipient_st'] = 'ME-1'\n",
    "D_2020_ME_new.loc[D_2020_ME_new['recipient_city'].isin(ME_2_2020), 'recipient_st'] = 'ME-2'\n",
    "# D_2024_ME_new = None\n",
    "\n",
    "\n",
    "# R_2024\n",
    "R_2024_NE_new = party_spending_dfs['2024_R'][party_spending_dfs['2024_R']['recipient_st'] == 'NE'].copy()\n",
    "R_2024_NE_new.loc[R_2024_NE_new['recipient_city'].isin(NE_1_2024), 'recipient_st'] = 'NE-1'\n",
    "R_2024_NE_new.loc[R_2024_NE_new['recipient_city'].isin(NE_2_2024), 'recipient_st'] = 'NE-2'\n",
    "R_2024_NE_new.loc[R_2024_NE_new['recipient_city'].isin(NE_3_2024), 'recipient_st'] = 'NE-3'\n",
    "# R_2024_NE_new = None \n",
    "\n",
    "R_2024_ME_new = party_spending_dfs['2024_R'][party_spending_dfs['2024_R']['recipient_st'] == 'ME'].copy()\n",
    "R_2024_ME_new.loc[R_2024_ME_new['recipient_city'].isin(ME_1_2024), 'recipient_st'] = 'ME-1'\n",
    "R_2024_ME_new.loc[R_2024_ME_new['recipient_city'].isin(ME_2_2024), 'recipient_st'] = 'ME-2'\n",
    "# R_2024_ME_new = None\n",
    "\n",
    "# D_2024\n",
    "D_2024_NE_new = party_spending_dfs['2024_D'][party_spending_dfs['2024_D']['recipient_st'] == 'NE'].copy()\n",
    "D_2024_NE_new.loc[D_2024_NE_new['recipient_city'].isin(NE_1_2024), 'recipient_st'] = 'NE-1'\n",
    "D_2024_NE_new.loc[D_2024_NE_new['recipient_city'].isin(NE_2_2024), 'recipient_st'] = 'NE-2'\n",
    "D_2024_NE_new.loc[D_2024_NE_new['recipient_city'].isin(NE_3_2024), 'recipient_st'] = 'NE-3'\n",
    "# D_2024_NE_new = None\n",
    "\n",
    "D_2024_ME_new = party_spending_dfs['2024_D'][party_spending_dfs['2024_D']['recipient_st'] == 'ME'].copy()\n",
    "D_2024_ME_new.loc[D_2024_ME_new['recipient_city'].isin(ME_1_2024), 'recipient_st'] = 'ME-1'\n",
    "D_2024_ME_new.loc[D_2024_ME_new['recipient_city'].isin(ME_2_2024), 'recipient_st'] = 'ME-2'\n",
    "# D_2024_ME_new = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_spending_dfs['2008_R'] = pd.concat([party_spending_dfs['2008_R'], R_2008_NE_new, R_2008_ME_new])\n",
    "party_spending_dfs['2012_R'] = pd.concat([party_spending_dfs['2012_R'], R_2012_NE_new, R_2012_ME_new])\n",
    "party_spending_dfs['2016_R'] = pd.concat([party_spending_dfs['2016_R'], R_2016_NE_new, R_2016_ME_new])\n",
    "party_spending_dfs['2020_R'] = pd.concat([party_spending_dfs['2020_R'], R_2020_NE_new, R_2020_ME_new])\n",
    "party_spending_dfs['2024_R'] = pd.concat([party_spending_dfs['2024_R'], R_2024_NE_new, R_2024_ME_new])\n",
    "\n",
    "party_spending_dfs['2008_D'] = pd.concat([party_spending_dfs['2008_D'], D_2008_NE_new, R_2008_ME_new])\n",
    "party_spending_dfs['2012_D'] = pd.concat([party_spending_dfs['2012_D'], D_2012_NE_new, R_2012_ME_new])\n",
    "party_spending_dfs['2016_D'] = pd.concat([party_spending_dfs['2016_D'], D_2016_NE_new, R_2016_ME_new])\n",
    "party_spending_dfs['2020_D'] = pd.concat([party_spending_dfs['2020_D'], D_2020_NE_new, R_2020_ME_new])\n",
    "party_spending_dfs['2024_D'] = pd.concat([party_spending_dfs['2024_D'], D_2024_NE_new, R_2024_ME_new])\n",
    "\n",
    "# party_spending_dfs['2008_R']['recipient_st'].unique()\n",
    "# for year,df in party_spending_dfs.items():\n",
    "#     print(year, len(df['recipient_st'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AL',\n",
       " 'AR',\n",
       " 'AZ',\n",
       " 'CA',\n",
       " 'CO',\n",
       " 'CT',\n",
       " 'DC',\n",
       " 'FL',\n",
       " 'GA',\n",
       " 'IA',\n",
       " 'IL',\n",
       " 'IN',\n",
       " 'LA',\n",
       " 'MA',\n",
       " 'MD',\n",
       " 'ME',\n",
       " 'MN',\n",
       " 'MO',\n",
       " 'NC',\n",
       " 'NE',\n",
       " 'NH',\n",
       " 'NJ',\n",
       " 'NY',\n",
       " 'OK',\n",
       " 'PA',\n",
       " 'SC',\n",
       " 'TN',\n",
       " 'TX',\n",
       " 'VA',\n",
       " 'SD',\n",
       " 'WA',\n",
       " 'WI',\n",
       " 'WY',\n",
       " 'OH',\n",
       " 'WV',\n",
       " 'AK',\n",
       " 'DE',\n",
       " 'HI',\n",
       " 'ID',\n",
       " 'KS',\n",
       " 'KY',\n",
       " 'MI',\n",
       " 'MS',\n",
       " 'MT',\n",
       " 'ND',\n",
       " 'NM',\n",
       " 'NV',\n",
       " 'OR',\n",
       " 'RI',\n",
       " 'UT',\n",
       " 'VT',\n",
       " 'NE-1',\n",
       " 'NE-2',\n",
       " 'NE-3',\n",
       " 'ME-1',\n",
       " 'ME-2']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.extend(['NE-1', 'NE-2', 'NE-3', 'ME-1', 'ME-2'])\n",
    "# states.sort()\n",
    "# states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we check to see if any states/DC are missing data, and see that several are missing entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008_R 55 1\n",
      "2008_D 56 0\n",
      "2012_R 56 0\n",
      "2012_D 55 1\n",
      "2016_R 55 1\n",
      "2016_D 56 0\n",
      "2020_R 54 2\n",
      "2020_D 55 1\n",
      "2024_R 52 4\n",
      "2024_D 53 3\n"
     ]
    }
   ],
   "source": [
    "for year in party_spending_dfs:\n",
    "    print(year, len(party_spending_dfs[year]['recipient_st'].unique()), 56-len(party_spending_dfs[year]['recipient_st'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check to see if any states are missing. We see that several are, so we add them to a list as a tuple of the state missing and the year_party. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008_R NE-3\n",
      "2012_D NE-3\n",
      "2016_R NE-3\n",
      "2020_R NE-1\n",
      "2020_R NE-3\n",
      "2020_D NE-1\n",
      "2024_R SD\n",
      "2024_R NE-1\n",
      "2024_R NE-3\n",
      "2024_R ME-2\n",
      "2024_D SD\n",
      "2024_D NE-1\n",
      "2024_D ME-2\n"
     ]
    }
   ],
   "source": [
    "# print(spending_dfs['2024']['recipient_st'].unique())\n",
    "# print(party_spending_dfs['2024_R'][party_spending_dfs['2024_R']['recipient_st'] == 'SD'])\n",
    "\n",
    "missed_states = []\n",
    "\n",
    "for year, df in party_spending_dfs.items():\n",
    "    for state in states:\n",
    "        if state not in df['recipient_st'].unique():\n",
    "            print(year, state)\n",
    "            missed_states.append((year, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the total spend in each state by each candiate. We then tag it with the state and year (year is in the form {year}_{R|D}, R or D for republican or democrat) for compiling it all into one dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_years = list(party_spending_dfs.keys())\n",
    "\n",
    "for year in party_years:\n",
    "    # print(len(spending_dfs[year]['recipient_st'].unique()))\n",
    "    state_sums[year] = party_spending_dfs[year].groupby('recipient_st').sum('disb_amt').sort_values('disb_amt')\n",
    "    state_sums[year] = state_sums[year].drop('file_num', axis=1)\n",
    "\n",
    "\n",
    "for year, st_sum in state_sums.items():\n",
    "    st_sum['state_year'] = st_sum.index + f\"_{year}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next add the missing states as 0 dollars spent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year,state in missed_states:\n",
    "    state_sums[year].loc[state]= [0, f'{state}_{year}']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then combine all dataframes to get the total spend in each state per candidate for each year, we see that there are 560 entires, which matches 10 candidates and 56 states + DC + districts in Maine and Nebraska. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disb_amt</th>\n",
       "      <th>state_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipient_st</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>2.982530e+03</td>\n",
       "      <td>ND_2008_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>4.573600e+03</td>\n",
       "      <td>WY_2008_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>6.016700e+03</td>\n",
       "      <td>ID_2008_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI</th>\n",
       "      <td>6.673290e+03</td>\n",
       "      <td>HI_2008_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>6.685440e+03</td>\n",
       "      <td>DE_2008_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>1.399371e+08</td>\n",
       "      <td>GA_2024_D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>2.110289e+08</td>\n",
       "      <td>DC_2024_D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>SD_2024_D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE-1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NE-1_2024_D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ME-2_2024_D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  disb_amt   state_year\n",
       "recipient_st                           \n",
       "ND            2.982530e+03    ND_2008_R\n",
       "WY            4.573600e+03    WY_2008_R\n",
       "ID            6.016700e+03    ID_2008_R\n",
       "HI            6.673290e+03    HI_2008_R\n",
       "DE            6.685440e+03    DE_2008_R\n",
       "...                    ...          ...\n",
       "GA            1.399371e+08    GA_2024_D\n",
       "DC            2.110289e+08    DC_2024_D\n",
       "SD            0.000000e+00    SD_2024_D\n",
       "NE-1          0.000000e+00  NE-1_2024_D\n",
       "ME-2          0.000000e+00  ME-2_2024_D\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_state_sums_df = pd.concat(state_sums.values())\n",
    "all_state_sums_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
